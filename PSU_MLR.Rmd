---
title: "PSU_MLR"
author: "Sam Colon"
date: "10/13/2017"
output: rmarkdown::github_document 
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE,
fig.path = "R_practice/unnamed-chunk-")
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r}
data <- read.csv('brain.csv')
head(data)
library(dplyr)
data_subset <- subset(data, select=c('PIQ', 'Weight','Height', 'MRICount'))
```

```{r}
#remove case with missing data
data_subset <- data_subset[-c(2,21),]
data_subset$MRICount <- data_subset$MRICount/10000 #divide var by 10,000
data_subset$Weight <- as.numeric(data_subset$Weight)
#convert weight from factor to numeric
```

```{r}
#make scatterplot matrix
pairs(data_subset)
```

###It appears there's collinearity in the height and weight, although PIQ doesn't look linearly related to the other variables.  

```{r}
##build multiple reg model for this dataset with PIQ as response variable,
model <- lm(PIQ ~ Weight+Height+MRICount, data=data_subset)
summary(model)
```

###Baby Bird Dataset
```{r}
bird_df <- read.table('babybirds.txt', header=TRUE)
pairs(bird_df)
bird_model <- lm(Vent ~ O2 + CO2, data=bird_df)
summary(bird_model)
```

###Soapsuds Example
```{r}
##soapsuds example, computing regression coefficients
soap_df <- read.table('soapsuds.txt', header=TRUE)
X <- as.matrix(soap_df['soap'])
X <- cbind(c(1,1,1,1,1,1,1),X) #add columns of 1s
XtX <- t(X) %*% X
Y <- soap_df$suds
XtY <- t(X) %*%Y
X_inv <- solve(XtX)
b <- X_inv%*%XtY
print(b)
```
###So we see the reg equation is suds = -2.68 + 9.500 * soap

###What if we purposely make columns linearly dependent
```{r, error=TRUE}
X2 <- data.frame(X)
X2$soap2 <- (X2$soap)*2
X2 <- as.matrix(X2)
X2tX2 <- t(X2) %*% X2
X2_inv <- solve(X2tX2) #we get error telling us matrix is singular, so inverse not computible.
```
###Pastry Sweetness Dataset: An experiment to assess how moisture content and sweetness of a pastry affects a taster's ratings of the pastry

```{r}
pastry_df <- read.csv('pastry.csv', header=TRUE)
pastry_df$Sweetness<- as.factor(pastry_df$Sweetness)
```

###Check correlation of predictor variables
```{r}
cor(pastry_df$Moisture, as.numeric(pastry_df$Sweetness), method="pearson")
cor.test(pastry_df$Moisture, as.numeric(pastry_df$Sweetness))
```
### We see 0 correlation.  

```{r}
library(ggplot2)
#Plot of Rating vs Moisure w/markers for both levels of sweetness. 
ggplot(pastry_df, aes(y = Rating, x= Moisture, colour= Sweetness, shape = Sweetness)) + geom_point() +geom_smooth(method='lm', fill=NA)
         
```                     
               
###Perform Simple and Multiple Regressions on Pastry Data
```{r}
moisture_model <- lm(Rating~ Moisture, data=pastry_df)
summary(moisture_model)
anova(moisture_model)
```

```{r}
pastry_df <- read.csv('pastry.csv', header=TRUE)
sweetness_model <- lm(Rating ~ Sweetness, data = pastry_df)
summary(sweetness_model)
anova(sweetness_model)
```



```{r}
pastry_df <- read.csv('pastry.csv', header=TRUE)
pastry_mlr <- lm(Rating ~ Moisture + Sweetness, data=pastry_df)
summary(pastry_mlr)
anova(pastry_mlr)
```

###Heart Rabbit Study
```{r}
rabbit_df <- read.csv('coolhearts.csv', header=TRUE)
rabbit_df$Group <- as.factor(rabbit_df$Group)
## Set Group 3 as reference level
rabbit_df <- within(rabbit_df, Group <-relevel(Group, ref=3))

#Build Reg Model
rabbit_lm <- lm(Infarction ~ factor(Group) + Area, data = rabbit_df)
summary(rabbit_lm)
```
###So, the regression equation is -.135 + .613*Area -.2435X2 - .0657X3

```{r}
#Plot of Infarction vs Area, with separate regression lines for each group
plot(Infarction~Area,rabbit_df,col=rabbit_df$Group,pch=20)
curve(predict(rabbit_lm,newdata=data.frame(Area=x,Group=1)),col=1,add=T)
curve(predict(rabbit_lm,newdata=data.frame(Area=x,Group=2)),col=2,add=T)
curve(predict(rabbit_lm,newdata=data.frame(Area=x,Group=3)),col=3,add=T)
legend('bottomright', levels(factor(rabbit_df$Group)), pch = 16, col =  which(levels(rabbit_df$Group) %in% levels(factor(rabbit_df$Group))))
```

###So, we see that as risk Area increases, size of Infarction tends to increase.  

###Calculating F-stat from regression output:
```{r}
full_anova <- anova(rabbit_lm) #sum of squares from full model

#reduced model
rabbit_lmr <- lm(Infarction ~ + Area, data = rabbit_df)
reduced_anova <- anova(rabbit_lmr)

#The general F-stat is calculated as (SSE(R)-SSE(F)/df(SSE(R)-df(SSE(F))))/(SSE(F)/df(SSE(F))

F_stat <- (reduced_anova$`Sum Sq`[2] -full_anova$`Sum Sq`[3])/(reduced_anova$Df[2]-full_anova$Df[3])/(full_anova$`Sum Sq`[3]/((full_anova$Df[3])))
F_stat

```

###We can explicitly calculate the p-value of this F_stat
```{r}
pf(F_stat, 2, 28, lower.tail=FALSE)
```
###Therefore, we can conclude that there is a statistically significant relationship between the method of cooling treatment and infarction size.

###We can also compute a partial F-statistic for variables x2 and x3 using sequential sum of squares, where we add x2 and x3 in order, given that x1 is already in the model
```{r}
rabbit_partialF<- lm(Infarction ~ + Area + X2 + X3 , data = rabbit_df)
anova_partial <- anova(rabbit_partialF)
rabbit_partialF
anova_partial
```
 
 
```{r}
# The F stat becomes SSR(X2, X3|X1)/(2)/(SSE(X2,X3|28)) or MSR(X2, X3|X1)/MSE(X1,X2,X3)

partial_Fstat<- ((anova_partial$`Sum Sq`[2]+ anova_partial$`Sum Sq`[3])/2)/((anova_partial$`Sum Sq`[4]/28))
partial_Fstat
```
###We see the resulting F-stat is the same

###To test if one slope parameter is 0, we can also use the t-test, as the square of the t-stat will equal the F-statistic
```{r}
#The test for testing area is:
rabbit_lm <- lm(Infarction ~ + Area + X2 + X3 , data = rabbit_df)
full_anova <-anova(rabbit_lm)
Area_Fstat <- (full_anova$`Sum Sq`[1]/full_anova $Df[1])/(full_anova$`Sum Sq`[4]/full_anova$Df[4])
Area_Fstat
pf(Area_Fstat, 1, 28, lower.tail=FALSE)

```

```{r}
summary <- summary(rabbit_lm)
#Get t-stat for Area and square it 
summary$coefficients[2,3] ^2
#We see it nearly equals F-stat above
```


###Sugar Beet Study
```{r}

#plot(Infarction~Area,rabbit_df,col=rabbit_df$Group,pch=20)
#curve(predict(rabbit_lm,newdata=data.frame(Area=x,Group=1)),col=1,add=T)

beet_df <-read.csv('beets.csv')
beet_df$Treat <- as.factor(beet_df$Treat)
beet_df <- within(beet_df, Treat <-relevel(Treat, ref=1))
```

```{r}
#Regression model
beet_lm <- lm(Yield ~ factor(Treat) + Nit, data = beet_df)


plot(Yield ~ Nit,beet_df,col=beet_df$Treat,pch=20)
curve(predict(beet_lm,newdata=data.frame(Nit=x,Treat=1)),col=1,add=T)
curve(predict(beet_lm,newdata=data.frame(Nit=x,Treat=2)),col=2,add=T)
curve(predict(beet_lm,newdata=data.frame(Nit=x,Treat=3)),col=3,add=T)
legend('bottomright', levels(factor(beet_df$Treat)), pch = 16, col =  which(levels(beet_df$Treat) %in% levels(factor(beet_df$Treat))))
```

###So, we see a clear linear relationship between amount of nitrogen and yield of sugar beets







